{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27dccb61",
   "metadata": {},
   "source": [
    "Data sourced from Kaggle competition [Natural Language Processing with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d54f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import core libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a9f6db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d110d740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from langdetect import detect\n",
    "\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "389922b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelling\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "992c4ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics/evaluation\n",
    "\n",
    "import scikitplot as skplt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f8f9a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the train and test sets\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test =  pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b056ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â combining the train and test sets for the purpose of EDA and Data Cleaning/Feature Engineering\n",
    "\n",
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0ff5bfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataframe Shape: (7613, 5)\n",
      "Test Dataframe Shape: (3263, 4)\n",
      "Combined Dataframe Shape: (10876, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Dataframe Shape: {}\".format(str(train.shape)))\n",
    "print(\"Test Dataframe Shape: {}\".format(str(test.shape)))\n",
    "print(\"Combined Dataframe Shape: {}\".format(str(df.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ed0e5598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0     1.0  \n",
       "1     1.0  \n",
       "2     1.0  \n",
       "3     1.0  \n",
       "4     1.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of tweets\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "aaf5faec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10876 entries, 0 to 10875\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        10876 non-null  int64  \n",
      " 1   keyword   10789 non-null  object \n",
      " 2   location  7238 non-null   object \n",
      " 3   text      10876 non-null  object \n",
      " 4   target    7613 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 425.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4aaee5",
   "metadata": {},
   "source": [
    "### Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b7524c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       87\n",
       "location    3638\n",
       "text           0\n",
       "target      3263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null values in the training set\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76503b",
   "metadata": {},
   "source": [
    "### Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "790ea358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'ablaze', 'accident', 'aftershock', 'airplane%20accident',\n",
       "       'ambulance', 'annihilated', 'annihilation', 'apocalypse',\n",
       "       'armageddon', 'army', 'arson', 'arsonist', 'attack', 'attacked',\n",
       "       'avalanche', 'battle', 'bioterror', 'bioterrorism', 'blaze',\n",
       "       'blazing', 'bleeding', 'blew%20up', 'blight', 'blizzard', 'blood',\n",
       "       'bloody', 'blown%20up', 'body%20bag', 'body%20bagging',\n",
       "       'body%20bags', 'bomb', 'bombed', 'bombing', 'bridge%20collapse',\n",
       "       'buildings%20burning', 'buildings%20on%20fire', 'burned',\n",
       "       'burning', 'burning%20buildings', 'bush%20fires', 'casualties',\n",
       "       'casualty', 'catastrophe', 'catastrophic', 'chemical%20emergency',\n",
       "       'cliff%20fall', 'collapse', 'collapsed', 'collide', 'collided',\n",
       "       'collision', 'crash', 'crashed', 'crush', 'crushed', 'curfew',\n",
       "       'cyclone', 'damage', 'danger', 'dead', 'death', 'deaths', 'debris',\n",
       "       'deluge', 'deluged', 'demolish', 'demolished', 'demolition',\n",
       "       'derail', 'derailed', 'derailment', 'desolate', 'desolation',\n",
       "       'destroy', 'destroyed', 'destruction', 'detonate', 'detonation',\n",
       "       'devastated', 'devastation', 'disaster', 'displaced', 'drought',\n",
       "       'drown', 'drowned', 'drowning', 'dust%20storm', 'earthquake',\n",
       "       'electrocute', 'electrocuted', 'emergency', 'emergency%20plan',\n",
       "       'emergency%20services', 'engulfed', 'epicentre', 'evacuate',\n",
       "       'evacuated', 'evacuation', 'explode', 'exploded', 'explosion',\n",
       "       'eyewitness', 'famine', 'fatal', 'fatalities', 'fatality', 'fear',\n",
       "       'fire', 'fire%20truck', 'first%20responders', 'flames',\n",
       "       'flattened', 'flood', 'flooding', 'floods', 'forest%20fire',\n",
       "       'forest%20fires', 'hail', 'hailstorm', 'harm', 'hazard',\n",
       "       'hazardous', 'heat%20wave', 'hellfire', 'hijack', 'hijacker',\n",
       "       'hijacking', 'hostage', 'hostages', 'hurricane', 'injured',\n",
       "       'injuries', 'injury', 'inundated', 'inundation', 'landslide',\n",
       "       'lava', 'lightning', 'loud%20bang', 'mass%20murder',\n",
       "       'mass%20murderer', 'massacre', 'mayhem', 'meltdown', 'military',\n",
       "       'mudslide', 'natural%20disaster', 'nuclear%20disaster',\n",
       "       'nuclear%20reactor', 'obliterate', 'obliterated', 'obliteration',\n",
       "       'oil%20spill', 'outbreak', 'pandemonium', 'panic', 'panicking',\n",
       "       'police', 'quarantine', 'quarantined', 'radiation%20emergency',\n",
       "       'rainstorm', 'razed', 'refugees', 'rescue', 'rescued', 'rescuers',\n",
       "       'riot', 'rioting', 'rubble', 'ruin', 'sandstorm', 'screamed',\n",
       "       'screaming', 'screams', 'seismic', 'sinkhole', 'sinking', 'siren',\n",
       "       'sirens', 'smoke', 'snowstorm', 'storm', 'stretcher',\n",
       "       'structural%20failure', 'suicide%20bomb', 'suicide%20bomber',\n",
       "       'suicide%20bombing', 'sunk', 'survive', 'survived', 'survivors',\n",
       "       'terrorism', 'terrorist', 'threat', 'thunder', 'thunderstorm',\n",
       "       'tornado', 'tragedy', 'trapped', 'trauma', 'traumatised',\n",
       "       'trouble', 'tsunami', 'twister', 'typhoon', 'upheaval',\n",
       "       'violent%20storm', 'volcano', 'war%20zone', 'weapon', 'weapons',\n",
       "       'whirlwind', 'wild%20fires', 'wildfire', 'windstorm', 'wounded',\n",
       "       'wounds', 'wreck', 'wreckage', 'wrecked'], dtype=object)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keyword.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8022c5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    42\n",
       "0.0    19\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to understand whether the null values in keyword have any relevance - they don't\n",
    "\n",
    "df[df.keyword.isnull()].target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7bcc08a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new category for the null keyword and location values\n",
    "\n",
    "df.fillna({'keyword': 'unknown', 'location': 'unknown'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "080f63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the keyword column\n",
    "\n",
    "df.replace({'keyword': '%20'}, {'keyword': '_'}, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b56ce0",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "dae61b9b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown            3638\n",
       "USA                 141\n",
       "New York            109\n",
       "United States        65\n",
       "London               58\n",
       "Canada               42\n",
       "Nigeria              40\n",
       "India                35\n",
       "Worldwide            35\n",
       "Los Angeles, CA      34\n",
       "UK                   33\n",
       "Kenya                32\n",
       "Washington, DC       31\n",
       "Mumbai               28\n",
       "United Kingdom       26\n",
       "Australia            25\n",
       "California           25\n",
       "Los Angeles          24\n",
       "Chicago, IL          23\n",
       "San Francisco        23\n",
       "Name: location, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# given how messy and the location column is, it's unlikely that we'll be able to clean it for modelling purposes\n",
    "\n",
    "df.location.value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1e0291",
   "metadata": {},
   "source": [
    "# Text\n",
    "\n",
    "### Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "62c30c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking that all tweets are in English\n",
    "\n",
    "# lang_series = df.text.apply(lambda x: detect(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4cbb31c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving lang_series as a joblib file\n",
    "\n",
    "# joblib.dump(lang_series, 'jlib_files/lang_series.jlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "88fd48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading lang_series jlib file\n",
    "\n",
    "lang_series = joblib.load('jlib_files/lang_series.jlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4c25239",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language'] = lang_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c09e030d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>10050</td>\n",
       "      <td>twister</td>\n",
       "      <td>instagram: bribriony</td>\n",
       "      <td>Drunk twister is so hard ????</td>\n",
       "      <td>0.0</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>9602</td>\n",
       "      <td>thunder</td>\n",
       "      <td>unknown</td>\n",
       "      <td>L B #Oklahoma #Thunder DURANT NBA ADIDAS OKLAH...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10320</th>\n",
       "      <td>9015</td>\n",
       "      <td>stretcher</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Mind salivation stretcher beds: KEGm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>9329</td>\n",
       "      <td>survive</td>\n",
       "      <td>EveryWhere</td>\n",
       "      <td>:: Survive??</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>3377</td>\n",
       "      <td>demolition</td>\n",
       "      <td>unknown</td>\n",
       "      <td>@czallstarwes more like demolition derby ??</td>\n",
       "      <td>0.0</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>578</td>\n",
       "      <td>arson</td>\n",
       "      <td>North-East Region, Singapore</td>\n",
       "      <td>@sayn_ae angel or arson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082</th>\n",
       "      <td>4873</td>\n",
       "      <td>explode</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Some guys explode ??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7755</th>\n",
       "      <td>449</td>\n",
       "      <td>armageddon</td>\n",
       "      <td>1996???????????</td>\n",
       "      <td>UNIVERSAL ORDER OF ARMAGEDDON http://t.co/3tY4mGm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8722</th>\n",
       "      <td>3668</td>\n",
       "      <td>destroy</td>\n",
       "      <td>unknown</td>\n",
       "      <td>People can't destroy you unless you let them.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904</th>\n",
       "      <td>5554</td>\n",
       "      <td>flattened</td>\n",
       "      <td>Keighley, England</td>\n",
       "      <td>Imagine getting flattened by Kurt Zouma</td>\n",
       "      <td>0.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>136</td>\n",
       "      <td>accident</td>\n",
       "      <td>Alberta | Sask. | Montana</td>\n",
       "      <td>Suffield Alberta Accident https://t.co/bPTmlF4P10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8072</th>\n",
       "      <td>1476</td>\n",
       "      <td>body_bagging</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>Eish even drake killing niggas eish game is re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10160</th>\n",
       "      <td>8493</td>\n",
       "      <td>screaming</td>\n",
       "      <td>United States</td>\n",
       "      <td>SCREAMING BECAUSE 5SOS IS IN TX\\n@5SOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>1491</td>\n",
       "      <td>body_bags</td>\n",
       "      <td>LONG ISLAND, NY</td>\n",
       "      <td>BODY BAGS! https://t.co/0McXc68GZD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5880</th>\n",
       "      <td>8399</td>\n",
       "      <td>sandstorm</td>\n",
       "      <td>United States</td>\n",
       "      <td>I liked a @YouTube video http://t.co/xR3xJJ8gJ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>da</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4087</th>\n",
       "      <td>5808</td>\n",
       "      <td>hail</td>\n",
       "      <td>Brasil, Fortaleza ce</td>\n",
       "      <td>Seen on Fahlo:#WCW All Hail the QueenÃ¥Ã?? http...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>6400</td>\n",
       "      <td>hurricane</td>\n",
       "      <td>@potteratthedisc</td>\n",
       "      <td>Hurricane 30STM quem lembra</td>\n",
       "      <td>1.0</td>\n",
       "      <td>fr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>214</td>\n",
       "      <td>airplane_accident</td>\n",
       "      <td>Eagle Pass, Texas</td>\n",
       "      <td>Mexican airplane accident in Ocampo Coahuila M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>5763</td>\n",
       "      <td>forest_fires</td>\n",
       "      <td>Boise, Idaho</td>\n",
       "      <td>8-5-2015 - 4:30 P.M. - Progress Being Made on ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>966</td>\n",
       "      <td>blaze</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Craving slurpees ;-;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id            keyword                      location  \\\n",
       "7011   10050            twister          instagram: bribriony   \n",
       "6703    9602            thunder                       unknown   \n",
       "10320   9015          stretcher                       unknown   \n",
       "6522    9329            survive                    EveryWhere   \n",
       "2347    3377         demolition                       unknown   \n",
       "401      578              arson  North-East Region, Singapore   \n",
       "9082    4873            explode                       unknown   \n",
       "7755     449         armageddon               1996???????????   \n",
       "8722    3668            destroy                       unknown   \n",
       "3904    5554          flattened             Keighley, England   \n",
       "94       136           accident     Alberta | Sask. | Montana   \n",
       "8072    1476       body_bagging                     Cape Town   \n",
       "10160   8493          screaming                 United States   \n",
       "1027    1491          body_bags               LONG ISLAND, NY   \n",
       "5880    8399          sandstorm                 United States   \n",
       "4087    5808               hail          Brasil, Fortaleza ce   \n",
       "4503    6400          hurricane              @potteratthedisc   \n",
       "7677     214  airplane_accident             Eagle Pass, Texas   \n",
       "4056    5763       forest_fires                  Boise, Idaho   \n",
       "7908     966              blaze                       unknown   \n",
       "\n",
       "                                                    text  target language  \n",
       "7011                       Drunk twister is so hard ????     0.0       de  \n",
       "6703   L B #Oklahoma #Thunder DURANT NBA ADIDAS OKLAH...     0.0       de  \n",
       "10320               Mind salivation stretcher beds: KEGm     NaN       da  \n",
       "6522                                        :: Survive??     0.0       hr  \n",
       "2347         @czallstarwes more like demolition derby ??     0.0       da  \n",
       "401                              @sayn_ae angel or arson     0.0       cy  \n",
       "9082                                Some guys explode ??     NaN       fr  \n",
       "7755   UNIVERSAL ORDER OF ARMAGEDDON http://t.co/3tY4mGm     NaN       de  \n",
       "8722       People can't destroy you unless you let them.     NaN       fr  \n",
       "3904             Imagine getting flattened by Kurt Zouma     0.0       no  \n",
       "94     Suffield Alberta Accident https://t.co/bPTmlF4P10     1.0       ca  \n",
       "8072   Eish even drake killing niggas eish game is re...     NaN       tl  \n",
       "10160             SCREAMING BECAUSE 5SOS IS IN TX\\n@5SOS     NaN       de  \n",
       "1027                  BODY BAGS! https://t.co/0McXc68GZD     0.0       de  \n",
       "5880   I liked a @YouTube video http://t.co/xR3xJJ8gJ...     0.0       da  \n",
       "4087   Seen on Fahlo:#WCW All Hail the QueenÃ¥Ã?? http...     0.0       de  \n",
       "4503                         Hurricane 30STM quem lembra     1.0       fr  \n",
       "7677   Mexican airplane accident in Ocampo Coahuila M...     NaN       ca  \n",
       "4056   8-5-2015 - 4:30 P.M. - Progress Being Made on ...     1.0       de  \n",
       "7908                                Craving slurpees ;-;     NaN       nl  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.language != 'en'].sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88469b7",
   "metadata": {},
   "source": [
    "It seems that the language detector function isn't doing a very good job of picking up some of the tweets' language. Regardless, it seems that all of the tweets are in English so we don't have to worry about dealing with other languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "79a1d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping language column from dataset\n",
    "\n",
    "df.drop('language', 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d1000",
   "metadata": {},
   "source": [
    "### Hash-tag extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f79f5400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our',\n",
       " 'Deeds',\n",
       " 'are',\n",
       " 'the',\n",
       " 'Reason',\n",
       " 'of',\n",
       " 'this',\n",
       " '#earthquake',\n",
       " 'May',\n",
       " 'ALLAH',\n",
       " 'Forgive',\n",
       " 'us',\n",
       " 'all']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "91c57969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_tags(x):\n",
    "    ht_list = []\n",
    "    for word in x.split():\n",
    "        if word[0] == '#':\n",
    "            ht_list.append(word.lower().replace('#',''))\n",
    "    return ht_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a4e36f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_tags = df.text.apply(hash_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cd430675",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hash_tags = hash_tags.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bc42bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_dict = {}\n",
    "\n",
    "for lst in hash_tags:\n",
    "    if len(lst) != 0:\n",
    "        for ht in lst:\n",
    "            if ht in ht_dict.keys():\n",
    "                ht_dict[ht] += 1\n",
    "            else:\n",
    "                ht_dict[ht] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7380aab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_df = pd.DataFrame.from_dict(ht_dict, orient = 'index', columns=[\"appearances\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2ccc4d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2700, 1)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f648e511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appearances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hot</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prebreak</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hiroshima</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>???</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>??</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nowplaying</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>islam</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbbo</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emmerdale</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jobs</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isis</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>terrorism</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuclear</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yyc</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japan</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            appearances\n",
       "news                 92\n",
       "hot                  42\n",
       "best                 41\n",
       "prebreak             41\n",
       "hiroshima            33\n",
       "???                  31\n",
       "??                   28\n",
       "nowplaying           25\n",
       "earthquake           24\n",
       "islam                22\n",
       "gbbo                 20\n",
       "world                20\n",
       "emmerdale            18\n",
       "jobs                 17\n",
       "isis                 17\n",
       "terrorism            16\n",
       "nuclear              15\n",
       "yyc                  15\n",
       "japan                14\n",
       "bbc                  14"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht_df.sort_values('appearances',ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd648320",
   "metadata": {},
   "source": [
    "It seems as though it's not much use trying to categorise the hash-tags. There are 2700 different hash-tags in the dataset, which is too broad a range. When we look at the hash-tags that appear the most, they still have a very small number of apparances, which wouldn't be of much to use if we were to use it as a predictor variable. \n",
    "\n",
    "For now, I'm just going to use the meta-data of how many hash-tags appear in each tweet. I don't expect this to be a super-useful predictor, but I'm optimistic that it might add some value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "06cd3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hashtags'] = num_hash_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "591505b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  unknown  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  unknown  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  unknown  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  unknown  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  unknown  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  hashtags  \n",
       "0     1.0         1  \n",
       "1     1.0         0  \n",
       "2     1.0         0  \n",
       "3     1.0         1  \n",
       "4     1.0         2  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ed2c20",
   "metadata": {},
   "source": [
    "### Creating new features: length of tweet, number of words and average word length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04622f45",
   "metadata": {},
   "source": [
    "### SHOULD WE TAKE OUT URLS BEFORE DOING THIS SECTION?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3b8d806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5965494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_characters'] = df.text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5d60b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(tweet):   \n",
    "    no_punct = ''.join([x for x in tweet if x not in string.punctuation])\n",
    "    word_lst = no_punct.split()      \n",
    "    return len(word_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "93c045ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_words'] = df.text.apply(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3277985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ''.join([x for x in 'Our Deeds are the Reason of this #earthquake ' if x not in string.punctuation]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "62df9612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(map(len, words))/len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "970be5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ave_word_length(tweet):\n",
    "    no_punct = ''.join([x for x in tweet if x not in string.punctuation])\n",
    "    word_lst = no_punct.split()\n",
    "    return sum(map(len, word_lst))/len(word_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4b27aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_av_word_length'] = df.text.apply(ave_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8807d274",
   "metadata": {},
   "source": [
    "### Expanding contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bb7afb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_no_contr'] = df.text.apply(lambda x: ' '.join([contractions.fix(word) for word in x.split()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd3b3b",
   "metadata": {},
   "source": [
    "### Tokenizing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3c1665ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized'] = df.text_no_contr.apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "31ac303b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_characters</th>\n",
       "      <th>tweet_words</th>\n",
       "      <th>text_no_contr</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>13</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>[Our, Deeds, are, the, Reason, of, this, #, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>[Forest, fire, near, La, Ronge, Sask, ., Canada]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>[All, residents, asked, to, 'shelter, in, plac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>[13,000, people, receive, #, wildfires, evacua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>16</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>[Just, got, sent, this, photo, from, Ruby, #, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  keyword location                                               text  \\\n",
       "0   1  unknown  unknown  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4  unknown  unknown             Forest fire near La Ronge Sask. Canada   \n",
       "2   5  unknown  unknown  All residents asked to 'shelter in place' are ...   \n",
       "3   6  unknown  unknown  13,000 people receive #wildfires evacuation or...   \n",
       "4   7  unknown  unknown  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  hashtags  tweet_characters  tweet_words  \\\n",
       "0     1.0         1                69           13   \n",
       "1     1.0         0                38            7   \n",
       "2     1.0         0               133           22   \n",
       "3     1.0         1                65            8   \n",
       "4     1.0         2                88           16   \n",
       "\n",
       "                                       text_no_contr  \\\n",
       "0  Our Deeds are the Reason of this #earthquake M...   \n",
       "1             Forest fire near La Ronge Sask. Canada   \n",
       "2  All residents asked to 'shelter in place' are ...   \n",
       "3  13,000 people receive #wildfires evacuation or...   \n",
       "4  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [Our, Deeds, are, the, Reason, of, this, #, ea...  \n",
       "1   [Forest, fire, near, La, Ronge, Sask, ., Canada]  \n",
       "2  [All, residents, asked, to, 'shelter, in, plac...  \n",
       "3  [13,000, people, receive, #, wildfires, evacua...  \n",
       "4  [Just, got, sent, this, photo, from, Ruby, #, ...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa283f7",
   "metadata": {},
   "source": [
    "### Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1465374b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c640407",
   "metadata": {},
   "source": [
    "### Experimenting with tweet-preprocessor package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bad63853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessor as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "206b6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet_tokenized'] = df.text.apply(lambda x:p.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c216e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a for-loop to add columns for the tweet meta-data features\n",
    "\n",
    "for feature in ['url', 'hashtag', 'smiley', 'mention']:\n",
    "    feature_counter = []\n",
    "    for tweet in df.tweet_tokenized:\n",
    "        counter = 0\n",
    "        for word in tweet.split():\n",
    "            if word == \"$\"+feature.upper()+\"$\":\n",
    "                counter += 1\n",
    "        feature_counter.append(counter)\n",
    "    df[\"tweet_\"+feature] = feature_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68071166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb465199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a69215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2cb75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac7e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2554f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef173565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01936082",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f875a6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945cd8ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c7b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa206db9",
   "metadata": {},
   "source": [
    "### To-do list:\n",
    "\n",
    "- create broader categories for the keyword and, potentially, location columns\n",
    "- use more visualizations through the data cleaning process (to start with: countvectorize before any data cleaning has started to show the words that appear the most frequently)\n",
    "\n",
    "\n",
    "#### Text Pre-processing\n",
    "\n",
    "- ~~check the language that the tweet is written in~~\n",
    "- remove digits and lower the text\n",
    "- ~~expand contractions~~\n",
    "- convert to lowercase\n",
    "- remove punctuation (maybe include meta-data for punctuation instead?)\n",
    "- tokenize words\n",
    "- lemmatize words\n",
    "- remove stop-words\n",
    "- ~~hashtag extraction~~\n",
    "\n",
    "- does the text contain emojis?\n",
    "\n",
    "#### Feature Engineering\n",
    "\n",
    "- meta-data\n",
    "    - - ~~how many hash-tags each tweet contains~~\n",
    "    - ~~no. of emojis~~\n",
    "    - ~~number of words~~\n",
    "    - ~~number of characters~~\n",
    "- sentiment analysis (textblob)\n",
    "- average word length\n",
    "- use spacy to extract location from location variable\n",
    "\n",
    "#### EDA\n",
    "\n",
    "- word clouds for each target variable\n",
    "- seperate the below by each target variable\n",
    "    - number of characters in each tweet\n",
    "    - average word length in each sentence\n",
    "    - most commonly appearing ngrams of various lenghts\n",
    "    - textblob for sentiment analysis\n",
    "    - use speech tagging\n",
    "    - frequency of most common words\n",
    "    - number of words with a given number of appearances\n",
    "    \n",
    "#### Other\n",
    "\n",
    "- Research the use of LDA and NMF\n",
    "    \n",
    "    \n",
    "Useful articles: \n",
    "\n",
    "https://towardsdatascience.com/preprocessing-text-data-using-python-576206753c28\n",
    "\n",
    "https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529e\n",
    "\n",
    "https://medium.com/spatial-data-science/how-to-extract-locations-from-text-with-natural-language-processing-9b77035b3ea4\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
